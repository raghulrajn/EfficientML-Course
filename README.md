# TinyML and Efficient Deep Learning Computing

This course introduces efficient AI computing techniques that enable powerful deep learning applications on resource-constrained devices. Topics include model compression, pruning, quantization, neural architecture search, distributed training, data/model parallelism, gradient compression, and on-device fine-tuning. It also introduces application-specific acceleration techniques for large language models and diffusion models.
[Link to course](https://efficientml.ai/)

## Lab 1 - Pruning
- Implement and apply fine-grained pruning
- Implement and apply channel pruning
- Performance improvement (such as speedup) from pruning
- Understand the differences and tradeoffs between these pruning approaches
